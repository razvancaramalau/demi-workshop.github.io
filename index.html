<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">


<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>2nd Workshop in Data Engineering in Medical Imaging (DEMI) @ MICCAI 2024  </title>
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" sizes="(max-width: 150px) 150px,
    (max-width: 150px)" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#C70039">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <link rel="icon" type="image/png" href="/assets/images/demi_logo2.png">
  <body style="text-align: justify;">

    <a id="skip-to-content" href="#content">Skip to the content.</a>
    <header class="page-header" role="banner">
        <div>
          <h1 class="project-name">Data Engineering in Medical Imaging (DEMI) </h1>
          <img src="/assets/images/demi_logo2.png" alt="demi" style=”max-width:640px;max-height:320px;" class="page-header"/>
        </div>  

      <div class="row">
        <img src="/assets/images/webpage/miccai2024-logo.png" alt="miccai2023-logo" style=”max-width:150px;max-height:150px;" id="hp"/>
        <div class="column">
        <h2 class="project-tagline"><MICCAI2023> DEMI @ MICCAI2024 Workshop, October, 2024 </h2>  
        </div>
        <div class="column">
        <a href="#Workshop themes" class="btn"> <strong>Workshop Themes</strong></a>
        <a href="#Keynote speakers" class="btn"> <strong>Keynote Speakers</strong></a>
        <a href="#Important Dates" class="btn"> <strong>Important dates </strong></a>
        <a href="#Submission" class="btn"> <strong>Submission</strong></a>
        <a href="#Workshop sessions" class="btn"> <strong>Sessions/Agenda</strong></a>
        </div>
      </div>
        </header>


        <main id="content" class="main-content" role="main">
          <h1 id="New">Recent updates</h1>
          <ul> 
            <!-- <li><p align="justify"> <strong> Deadline open till 10th June 2023  </strong> --> 
            <li><p align="justify"> <strong> <a href="#Workshop sessions"> <strong>Program  update</strong></a>  </strong>  </p>  </li>
            <li><p align="justify"> <strong> Submissions opens on TBD <!--</strong>:  <a href="https://cmt3.research.microsoft.com/DEMI2023"> CMT for DEMI@MICCAI2023</a></p>  </li> -->
            <!-- <li><p align="justify"> <strong> Submit your 8-10 page MICCAI format paper here (please read <a href="#Submission"> <strong>submission instructions</strong></a>) </strong> </p>  </li> -->
          </ul>
            
        <!-- <h1 id="Workshop sessions">Workshop Programme</h1>
            <p> <strong> 8:00 AM </strong>:  Poster setup </p>
            <p> <strong> 8:30 AM </strong>:  Opening: Welcome & Introduction </p>
            <p> <strong> 8:40 AM </strong>:  Poster Teaser I (in person) </p>
            <ul style="font-size: smaller; line-height: 1;">
            <li>Paper 8: Efficient Large Scale Medical Image Dataset Preparation for Machine Learning Applications</li>
            <li>Paper 13: Procedurally Generated Colonoscopy and Laparoscopy Data For Improved Model Training Performance</li>
            <li>Paper 18: Task-guided Domain Gap Reduction for Monocular Depth Prediction in Endoscopy</li>
            <li>Paper 14: Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining</li>
            <li>Paper 6: Pre-training with simulated ultrasound images for breast mass segmentation and classification</li>
            <li>Paper 15: A Study on Using Transformer Encoding Techniques to Optimize Data-driven Volume-to-Surface Registration for Minimally Invasive Liver Interventions</li>
    
            </ul>
            <p> <strong> 9:15 AM </strong>:  Keynote 1:  <a href="#JZOU"> Prof. James Zou (Stanford University) </strong></a> </p>
            <p> <strong> 10:00 AM </strong>:  Coffee Break & Poster Discussion </p>
            <p> <strong> 11:00 AM </strong>:  Poster Teaser II (online)  </p>
                 <ul style="font-size: smaller; line-height: 1;">
            <li>Paper 5: A Client-server Deep Federated Learning for Cross-domain Surgical Image Segmentation</li>
            <li>Paper 1: Weakly Supervised Medical Image Segmentation through Dense Combinations of Dense Pseudo-Labels</li>
            <li>Paper 11: A Self-supervised Approach for Detecting the Edges of Haustral Folds in Colonoscopy Video</li>
            <li>Paper 16: Vision Transformer-based Self-Supervised Learning for Ulcerative Colitis Grading in Colonoscopy</li>
                     <li>Paper 4: Whole Slide Multiple Instance Learning for Predicting Axillary Lymph Node Metastasis</li>
            </ul>
            <p> <strong> 11:30 AM </strong>:  Keynote 2: <a href="#QDOU"> Prof. Qi Dou (The Chinese University of Hong Kong) </strong></a> </p>
            <p> <strong> 12:15 AM </strong>:  Awards & Concluding Remarks </p>
            <p> <strong> 12:30 AM </strong>:  Workshop ends </p> -->

            
        <h1 id="workshop-description">Workshop Description</h1>
            <p align="justify">Data engineering plays a vital role in advancing medical imaging research, where limited data availability poses a significant challenge. 
                To tackle this issue, the medical imaging community has adopted various techniques, including active learning, label and data augmentation, self-supervision, and synthetic data generation.</p>
<p align="justify">However, the potential of these methods has yet to be fully leveraged. Data augmentation, for instance, is often randomly chosen based on intuition. 
    Yet previous work has shown that it is crucial to jointly optimize the augmentations' complexity and affinity, i.e., how much the augmentation shifts the decision boundary of the clean baseline model. 
    Other studies suggest that not every synthetic example improves the model's generalizability, with some even hurting performance if not reasonably chosen. 
    Similarly, the effect of self-supervised pre-training methods on downstream tasks generally depends on the overlap between the pretext task and the downstream tasks. 
    For instance, a model trained to predict rotation angles will not be effective in rotationally invariant organs.   </p>  
<p align="justify">We witness various research efforts in the data engineering domain, but most are pursued in isolation. And many research questions in data engineering that are of utmost importance to the success of machine learning methods for medical image analysis remain unanswered. 
Some questions this workshop hopes to help answer are:
                <ul>

                
                <li>What data should we collect to train a model for a given medical task?</li>
                <li>How do we identify diverse and discriminative examples for a downstream task in complex biomedical datasets? For instance, do we need to annotate every frame in a surgical video? </li>
                <li>How do we identify the best augmentation strategy?</li>
                <li>What is the best way to spend a data labeling budget (time/money)? How much data should we collect, and how much of it should we label? </li>
                <li>How do we learn to synthesize data for a downstream medical task? </li>
                <li>How do we design suitable pretext tasks for a particular downstream task? </li>
                <li>And overall, how can we blend exisitng data-focused works to extract the most benefit from the data?</li>
                </ul>  

              
            </p>  
            <p align="justify"> The workshop invites researchers to submit their work in the field of medical imaging around the central theme of data engineering. Some themes we would like to explore include for instance:
            </p>  


            <h1 id="Workshop themes">Workshop themes</h1>
            <ol> 
              <li><p align="justify"> <strong>Data Augmentation and Label Augmentation in the Medical Domain:</strong> includes data augmentation through geometric transformations or application-aware policies. It also investigates data generated from virtual environments, phantoms, or generative models.
              </p></li>
              <li><p align="justify"> <strong>Active Learning and Active Synthesis:</strong> covers methods that find the most discriminative and diverse subset of unlabelled data to train a model for various clinical applications. Active synthesis is about generating synthetic data for a particular application.
              </p></li>
                
               <li><p align="justify"> <strong>Federated learning:</strong> distributed data management and learning to address privacy concerns and security, for instance, across institutions or countries. 
                </p></li>
                <li><p align="justify"> <strong>Multimodal learning:</strong> includes approaches to combine data from multiple sources and sensors (e.g. CT, MRI, endoscope, text, audio, depth, etc.)
                </p></li>
                <li><p align="justify"> <strong>Self-Supervised Learning Algorithms for Medical Downstream Tasks:</strong> investigates application-specific relevant pretext tasks for pre-training models in a self-supervised manner. 
                </p></li>
                <li><p align="justify"> <strong>
                 Large-scale data management and data quality assessment.</strong>
                </p></li>
            </ol>
            
          <h1 id="Keynote speakers">Keynote speakers</h1> 
        <p align="justify"> <strong>TBD</strong> </p>
        <!-- <p  id="JZOU" align="justify"> <strong>Prof. James Zou </strong></p></li>
        <p> Dr. James Zou is an Assistant Professor of Biomedical Data Science, CS and EE at Stanford University. 
            He is also the faculty director of Stanford AI4Health. He works on both improving the foundations of ML by making models more trustworthy and reliable as well as in-depth scientific and clinical applications. 
            Many of his innovations are widely used in tech and biotech industries.  
            He has received a Sloan Fellowship, an NSF CAREER Award, two Chan-Zuckerberg Investigator Awards, a Top Ten Clinical Achievement Award, several best paper awards, and faculty awards from Google, Amazon, Tencent and Adobe.
        </p>
        <p id="QDOU" align="justify"> <strong>Prof. Qi Dou </strong></p></li>
        <p> Dr. Qi Dou is an Assistant Professor with the Department of Computer Science & Engineering at The Chinese University of Hong Kong. 
            Her research interest lies in the interdisciplinary area of AI for healthcare with expertise in medical image analysis and robot-assisted surgery towards the goal of advancing disease diagnosis and intervention via machine intelligence. 
            In this area, Dr. Dou has published over a hundred publications with Google Scholar citations 19000+ and H-index 55. 
            Her research outputs have won a number of distinguished best paper awards including MedIA-MICCAI'17 Best Paper Award, IEEE ICRA 2021 Best Paper Award in Medical Robotics. 
            Dr. Dou received IEEE Engineering in Medicine & Biology Society Early Career Award 2023. 
            She served as Program Co-Chair of the major conferences of MICCAI, IPCAI, MIDL, and Associate Editor of top journals of Medical Image Analysis and IEEE Transactions on Medical Imaging.
        </p> -->
    

    
    <h1 id="Important Dates">Important Dates</h1>
    <!-- <p>Coming Soon</p> -->
   <p><strong>Paper submission begins:</strong> 2nd May 2024</p>
<!-- <p><strong>Submission deadline:</strong> <del>24th June 2024</del> <span style="color: red;">14th July 2023</span></p> -->
  <p><strong>Submission deadline:</strong> 24th June 2024</p>
<p><strong>Paper decision notification:</strong> 15th July 2024</p> <!--<span style="color: red;">28th July 2023</span></p>-->
    <p><strong>Camera ready submission:</strong> 1st August 2024</p>  <!-- <span style="color: red;">4th August 2023</span></p> -->
      <p><strong>Workshop day:</strong> 10th October 2024</p>
          
    <h1 id="Submission">Submission</h1>
    <!-- <p>Coming Soon</p> -->
    <p><strong>CMT submission website TBD<!--</strong>:  <a href="https://cmt3.research.microsoft.com/DEMI2023"> CMT for DEMI@MICCAI2023</a> </p>-->
    <p>Accepted papers will be published in a joint proceeding with the MICCAI 2024 conference. </p>
    <p>All papers should be formatted according to the <a href="https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines"> Lecture Notes in Computer Science templates</a>.</p>
    <p><span lang="EN-US">We recommend<strong> submission up to 8-pages and 2-pages of references (same as MICCAI main conference) for a double-blind peer review process</strong></span></p>
    <p>In addition, since the joint workshop has adhered to the <strong>double-blinded peer review process</strong>, we ask that you <strong>please follow the <a href="https://conferences.miccai.org/2024/en/PAPER-SUBMISSION-AND-REBUTTAL-GUIDELINES.html">MICCAI2024 anonymity guidelines</strong></a> when preparing your intial submission.</p> 


    <!-- <h1 id="Proceedings">Proceedings</h1>
    <p align="justify"><span style="font-size: 12pt ;" style="padding: 20px;"><br />
    <img src="/assets/images/webpage/LNCS-Logo.png" alt="LNCS" style="float:left" width="128" /> <p>Accepted papers will be published in LNCS as a separate DEMI 2023 (MICCAI Workshop), October 2023 proceeding </p>

  <h2>Accepted Papers</h2>
<ul>
        <li>
            <strong>Weakly Supervised Medical Image Segmentation through Dense Combinations of Dense Pseudo-Labels</strong><br>
            Ziyang Wang, Irina D Voiculescu
        </li>
        <li>
            <strong>Whole Slide Multiple Instance Learning for Predicting Axillary Lymph Node Metastasis</strong><br>
            Glejdis Shkëmbi, Johanna P Müller, Zhe Li, Katharina Breininger, Peter Schüffler, Bernhard Kainz
        </li>
        <li>
            <strong>A Client-server Deep Federated Learning for Cross-domain Surgical Image Segmentation</strong><br>
            Ronast Subedi, Rebati Raman Gaire, Sharib Ali, Anh Nguyen, Danail Stoyanov, Binod Bhattarai
        </li>
        <li>
            <strong>Pre-training with simulated ultrasound images for breast mass segmentation and classification</strong><br>
            Michal Byra, Ziemowit Klimonda, Jerzy Litniewski
        </li>
        <li>
            <strong>Efficient Large Scale Medical Image Dataset Preparation for Machine Learning Applications</strong><br>
            Stefan Denner, Jonas Scherer, Klaus Kades, Dimitrios Bounias, Philipp Schader, Lisa Kausch, Markus Bujotzek, Andreas Bucher, Tobias Penzkofer, Klaus H. Maier-Hein
        </li>
        <li>
            <strong>A Self-supervised Approach for Detecting the Edges of Haustral Folds in Colonoscopy Video</strong><br>
            Wenyue Jin, Rema Daher, Danail Stoyanov, Francisco Vasconcelos
        </li>
        <li>
            <strong>Procedurally Generated Colonoscopy and Laparoscopy Data For Improved Model Training Performance</strong><br>
            Thomas Dowrick, Matthew J Clarkson, João Ramalhinho, Long Chen, Juana González-Bueno Puyal
        </li>
        <li>
            <strong>Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining</strong><br>
            Bidur Khanal, Binod Bhattarai, Bishesh Khanal, Cristian Linte
        </li>
        <li>
            <strong>A Study on Using Transformer Encoding Techniques to Optimize Data-driven Volume-to-Surface Registration for Minimally Invasive Liver Interventions</strong><br>
            Michael A Young, Zixin Yang, Richard Simon, Cristian Linte
        </li>
        <li>
            <strong>Vision Transformer-based Self-Supervised Learning for Ulcerative Colitis Grading in Colonoscopy</strong><br>
            Ajay Pyatha, Ziang Xu, Sharib Ali
        </li>
        <li>
            <strong>Task-guided Domain Gap Reduction for Monocular Depth Prediction in Endoscopy</strong><br>
            Anita Rau, Binod Bhattarai, Lourdes Agapito, Danail Stoyanov
        </li>
    </ul> -->

      <h1 id="Organising committee">Organising committee</h1>
        <table>
          <tbody>
            <tr>
              <td><img src="/assets/images/organisers/4856_0317138.jpg" alt="Binod Bhattarai" width="300"  id="hp2"/></td>
              <td><img src="/assets/images/organisers/shariba.jpeg" alt="Sharib Ali" width="300"  id="hp2"/></td>
              <td><img src="/assets/images/organisers/anita.jpg" alt="Anita Rau" width="300" id="hp2"/></td>
            </tr>
            <tr>
              <td><a href="https://sites.google.com/view/bbinod">Binod Bhattarai</a><br />University of Aberdeen, UK</td>
              <td><a href="https://eps.leeds.ac.uk/computing/staff/11465/dr-sharib-ali">Sharib Ali</a><br /> University of Leeds, UK </td>
              <td><a href="https://profiles.stanford.edu/anita-rau">Anita Rau</a><br />Stanford University, USA
              </td>
            </tr>
            <tr>
              <td><img src="/assets/images/organisers/razvan.jpg" alt="Razvan Caramalau" width="300"  id="hp2" /></td>
              <td><img src="/assets/images/organisers/AnhNguyen.png" alt="anguyen"  width="300"  id="hp2"/></td>
              <td><img src="/assets/images/organisers/Prashnna.jpeg" alt="Prashnna" width="300" id="hp2"/></td>
            </tr>
            <tr>
              <td><a href="https://iris.ucl.ac.uk/iris/browse/profile?upi=RCARA82">Razvan Caramalau</a><br /> University College London, UK
              <td><a href="https://www.csc.liv.ac.uk/~anguyen/">Anh Nguyen</a><br /> University of Liverpool, UK</td>
                <td><a href="https://directory.statler.wvu.edu/faculty-staff-directory/prashnna-gyawali">Prashnna Gyawali</a><br /> West Virginia University, USA
                </td>
                
            </tr>
            <td><img src="/assets/images/organisers/ana.jpg" alt="ana-namburete" width="300" id="hp2"/></td>
            <td><img src="/assets/images/organisers/Dan.jpg" alt="Danail Stoyanov" width="300" id="hp2"></td>
            <tr>
              <td><a href="https://www.pmb.ox.ac.uk/person/professor-ana-namburete">Ana Namburete</a><br /> University of Oxford, UK
              </td>
              <td><a href="https://www.ucl.ac.uk/surgical-robot-vision/people/danail-stoyanov">Danail Stoyanov</a><br />University College London, UK
              </td>
            </tr>
          </tbody>
        </table>

<h1>Technical Program Committee</h2>
  <p><strong>TBD</strong></p> 
<!-- <table>
  <tr>
    <td>Adrian Krenzer (Julius Maximilian University of Würzburg)</td>
  </tr>
  <tr>
    <td>Annika Reinke (German Cancer Research Center)</td>
  </tr>
  <tr>
    <td>Bidur Khanal (Rochester Institute of Technology)</td>
  </tr>
  <tr>
    <td>Chloe He (University College London)</td>
  </tr>
  <tr>
    <td>Francisco Vasconcelos (University College London)</td>
  </tr>
  <tr>
    <td>Gilberto Ochoa-Ruiz (Tec de Monterrey)</td>
  </tr>
  <tr>
    <td>Jialang Xu (University College London)</td>
  </tr>
  <tr>
    <td>Jingxuan Kang (University of Liverpool)</td>
  </tr>
  <tr>
    <td>Josiah Aklilu (Stanford University)</td>
  </tr>
  <tr>
    <td>Mariia Dmitrieva (Queens Square Analytics London)</td>
  </tr>
  <tr>
    <td>Michal Byra (RIKEN Center for Brain Science)</td>
  </tr>
  <tr>
    <td>Prashnna Gyawali (Stanford University)</td>
  </tr>
  <tr>
    <td>Rumeysa Bodur (Imperial College London)</td>
  </tr>
  <tr>
    <td>Stefan Denner (German Cancer Research Center)</td>
  </tr>
  <tr>
    <td>Tianhong Dai (University of Aberdeen)</td>
  </tr>
  <tr>
    <td>Tudor Jianu (University of Liverpool)</td>
  </tr>
  <tr>
    <td>Ziyang Wang (Oxford University)</td>
  </tr>
</table> -->

<h1>Web and Publicity Chair</h2>
  <li><a href="https://www.naamii.org.np/teams/sandesh-pokhrel/">Sandesh Pokhrel, NAAMII, Nepal</a></li> 
        
  <h1 id="Sponsors">Sponsors</h1>
        <!-- <a href="https://fogsphere.com">
  <img src="/assets/images/webpage/fogsphere_logo.jpg" alt="Logo" style="float:left" width="256" />
            </a> -->
<div style="clear:both;"></div>
  <p>We are seeking additional ademic/industrial sponshorships. Please contact us for more details: <a href="mailto:demiworkshop23@gmail.com">demiworkshop23@gmail.com</a></p>

  <h1 id="Sponsors">Past Iterations</h1>
  <li><a href="https://demi-workshop.github.io/demi-workshop2023.github.io/">DEMI@MICCAI2023 </a></li>
    <footer class="site-footer">
        
      <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
    </footer>
        </main>
    </body>
</head>
